{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "# Check if the webcam is opened correctly \n",
    "if not cap.isOpened(): \n",
    "    raise IOError(\"Cannot open webcam\") \n",
    " \n",
    "while True: \n",
    "    ret, frame = cap.read() \n",
    "    frame = cv2.resize(frame, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA) \n",
    "    cv2.imshow('Input', frame) \n",
    " \n",
    "    c = cv2.waitKey(1) \n",
    "    if c == 27: \n",
    "        break \n",
    " \n",
    "cap.release() \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyboard Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_howto(): \n",
    "    print(\"\"\"\n",
    "        Change color space of the\n",
    "        input video stream using keyboard controls. The control keys are: \n",
    "            1. Grayscale - press 'g'\n",
    "            2. YUV - press 'y'\n",
    "            3. HSV - press 'h'\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_howto() \n",
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "# Check if the webcam is opened correctly \n",
    "if not cap.isOpened(): \n",
    "    raise IOError(\"Cannot open webcam\") \n",
    "\n",
    "cur_mode = None\n",
    "while True: \n",
    "    # Read the current frame from webcam \n",
    "    ret, frame = cap.read() \n",
    "\n",
    "    # Resize the captured image \n",
    "    frame = cv2.resize(frame, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_AREA) \n",
    "\n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27: \n",
    "        break \n",
    "\n",
    "    if c != -1 and c != 255 and c != cur_mode:\n",
    "        cur_mode = c \n",
    "\n",
    "    if cur_mode == ord('g'): \n",
    "        output = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "    elif cur_mode == ord('y'): \n",
    "        output = cv2.cvtColor(frame, cv2.COLOR_BGR2YUV) \n",
    "    elif cur_mode == ord('h'): \n",
    "        output = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) \n",
    "    else: \n",
    "        output = frame \n",
    "    cv2.imshow('Webcam', output) \n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MedianBlur Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images\\\\dp.jpg')\n",
    "output = cv2.medianBlur(img, ksize=7) \n",
    "plt.imshow(img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n",
      "Motion Found\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "# Check if the webcam is opened correctly \n",
    "if not cap.isOpened(): \n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "    \n",
    "old_frame = np.empty((720, 960, 3))\n",
    "\n",
    "while True: \n",
    "    # Read the current frame from webcam \n",
    "    ret, frame = cap.read() \n",
    "\n",
    "    # Resize the captured image \n",
    "    frame = cv2.resize(frame, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    if not np.array_equal(old_frame, frame):\n",
    "        print('Motion Found')\n",
    "    \n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27: \n",
    "        break \n",
    "    \n",
    "    cv2.imshow('Webcam', frame) \n",
    "    \n",
    "    old_frame = frame\n",
    "cap.release() \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blurr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "# Check if the webcam is opened correctly \n",
    "if not cap.isOpened(): \n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "    \n",
    "kernel_5 = np.ones((10,10), dtype=np.float32) / 100.0\n",
    "\n",
    "while True: \n",
    "    # Read the current frame from webcam \n",
    "    ret, frame = cap.read() \n",
    "    \n",
    "    output_frame = cv2.filter2D(frame, -1, kernel_5)\n",
    "    \n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27: \n",
    "        break \n",
    "    \n",
    "    cv2.imshow('Webcam', output_frame) \n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "# Check if the webcam is opened correctly \n",
    "if not cap.isOpened(): \n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "    \n",
    "while True: \n",
    "    # Read the current frame from webcam \n",
    "    ret, frame = cap.read() \n",
    "    old_frame = frame\n",
    "    \n",
    "    frame = cv2.resize(frame, None, fx=0.3, fy=0.3, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    frame[:,:,2] = 0\n",
    "    \n",
    "    frame[:,:,1] = 0\n",
    "    \n",
    "    for i in range(frame[:,:,0].shape[0]):\n",
    "        for j in range(frame[:,:,0].shape[1]):\n",
    "            if frame[:,:,0][i][j] < 100:\n",
    "                frame[:,:,0][i][j] = 0\n",
    "    \n",
    "    frame = cv2.resize(frame, None, fx=3, fy=3, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    \n",
    "#     for i in frame:\n",
    "#         for j in i:\n",
    "#             j[0] = 0\n",
    "#             j[1] = 0\n",
    "#             if j [2] < 150:\n",
    "#                 j[2] = 0\n",
    "    \n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27: \n",
    "        break \n",
    "    \n",
    "    cv2.imshow('Webcam', old_frame)\n",
    "    cv2.imshow('BlueFrame', frame)\n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vintage Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "# Check if the webcam is opened correctly \n",
    "if not cap.isOpened(): \n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "    \n",
    "k = 0\n",
    "\n",
    "while True: \n",
    "    # Read the current frame from webcam \n",
    "    ret, frame = cap.read() \n",
    "    c = cv2.waitKey(1)\n",
    "    rows, cols = frame.shape[:2]\n",
    "    \n",
    "    kernel_x = cv2.getGaussianKernel(cols,200) \n",
    "    kernel_y = cv2.getGaussianKernel(rows,200) \n",
    "    kernel = kernel_y * kernel_x.T \n",
    "    mask = 255 * kernel / np.linalg.norm(kernel) \n",
    "    output = np.copy(frame) \n",
    "\n",
    "    # applying the mask to each channel in the input image \n",
    "    for i in range(3): \n",
    "        output[:,:,i] = output[:,:,i] * mask \n",
    "        \n",
    "        \n",
    "    output = cv2.cvtColor(output, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    kernel_sharpen = np.array([[-1,-1,-1,-1,-1], \n",
    "                             [-1,2,2,2,-1], \n",
    "                             [-1,2,18,2,-1], \n",
    "                             [-1,2,2,2,-1], \n",
    "                             [-1,-1,-1,-1,-1]]) / 18.0 \n",
    " \n",
    "    # applying different kernels to the input image \n",
    "    output = cv2.filter2D(output, -1, kernel_sharpen) \n",
    "    \n",
    "    \n",
    "    if c == 27: \n",
    "        break \n",
    "    \n",
    "    cv2.imshow('Webcam', frame)\n",
    "    cv2.imshow('VintageFrame', output)\n",
    "    cv2.imwrite(\"Pics\\\\\"+str(k)+\".png\",output)\n",
    "    k = k + 1\n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
